\documentclass[12pt]{article}

\input{packages.tex}
\input{style.tex}

\begin{document}

\title{Further Properties of Determinants}
\author{Brian D.\ Fitzpatrick}
\date{\cite[\S1.6]{peterson}}

\maketitle

% \tableofcontents

\begin{sagesilent}
  latex.matrix_delimiters(left='[', right=']')
\end{sagesilent}

\begin{thm}[Theorem 1.21 in \cite{peterson}]
  A square matrix $A$ is invertible if and only if $\det(A)\neq 0$.
\end{thm}
\begin{proof}
  By \cite[Theorem 1.20]{peterson}, performing an elementary row operation $A\to
  B$ results in $\det(B)=\lambda\cdot\det(A)$ where $\lambda\neq 0$. Since
  $\rref(A)$ is obtained from $A$ by elementary row operations, it follows that
  $\det(\rref A)=\lambda\cdot\det(A)$. Since $A$ is invertible if and only if
  $\det(\rref A)\neq 0$, it follows that $A$ is invertible if and only if
  $\det(A)\neq 0$.
\end{proof}

\begin{sagesilent}
  A = matrix([[1,3,4],[2,0,1],[0,0,2]])
  A12 = A.delete_rows([0]).delete_columns([1])
\end{sagesilent}
\begin{ex}
  Note that $\det\sage{A}=(-3)\det\sage{A12}=(-3)(2)(2)\neq 0$. Hence $\sage{A}$
  is invertible.
\end{ex}

\newpage
\begin{thm}[Lemma 1.22 in \cite{peterson}]
  Elementary matrices have determinants
  \begin{align*}
    \det[R_i\leftrightarrow R_j] &= -1 \\
    \det[\lambda\cdot R_i\to R_i] &= \lambda \\
    \det[R_i+\lambda\cdot R_j\to R_i] &= 1
  \end{align*}
\end{thm}

\begin{sagesilent}
  E1 = elementary_matrix(3, row1=1, row2=2)
  E2 = elementary_matrix(3, row1=1, scale=-3)
  E3 = elementary_matrix(3, row1=0, row2=1, scale=2)
\end{sagesilent}
\begin{ex}
  In the $3\times 3$ case we have
  \begin{align*}
    \det[R_2\leftrightarrow R_3] &= \det\sage{E1}=\sage{E1.det()} \\
    \det[-3\cdot R_2\to R_2] &= \det\sage{E2} = \sage{E2.det()} \\
    \det[R_1+2\cdot R_2\to R_1] &= \det\sage{E3} = \sage{E3.det()}
  \end{align*}
\end{ex}

\newpage

\begin{thm}[Theorem 1.24 in \cite{peterson}]
  If $A$ and $B$ are square matrices, then $\det(AB)=\det(A)\det(B)$.
\end{thm}

\begin{thm}[Corollary 1.25 in \cite{peterson}]
  If $A$ is invertible, then $\displaystyle\det(A^{-1})=\frac{1}{\det(A)}$.
\end{thm}
\begin{proof}
  Note that
  \[
  \det(A^{-1})\det(A)=\det(A^{-1}A)=\det(I)=1
  \]
  so that $\displaystyle\det(A^{-1})=\frac{1}{\det(A)}$.
\end{proof}

\newpage
\begin{definition}
  The \emph{cofactor matrix} of a square matrix $A$ is the $n\times n$ matrix
  \[
  C = 
  \begin{bmatrix}
    C_{11} & C_{12} & \cdots & C_{1n} \\
    C_{21} & C_{22} & \cdots & C_{2n} \\
    \vdots & \vdots & \ddots & \vdots \\
    C_{n1} & C_{n2} & \cdots & C_{nn}
  \end{bmatrix}
  \]
  The \emph{adjoint} of $A$ is 
  \[
  \adj(A)=C^\top=
  \begin{bmatrix}
    C_{11} & C_{21} & \cdots & C_{n1} \\
    C_{11} & C_{22} & \cdots & C_{n2} \\
    \vdots & \vdots & \ddots & \vdots \\
    C_{1n} & C_{2n} & \cdots & C_{nn}
  \end{bmatrix}
  \]
\end{definition}

\begin{sagesilent}
  var('a b c d')
  A = matrix([[a,b],[c,d]])
\end{sagesilent}
\begin{ex}
  For $\sage{A}$ we have
  \begin{align*}
    C_{11} &= d & C_{12} &= -c \\
    C_{21} &= -b & C_{22} &= a
  \end{align*}
  Hence
  \begin{align*}
    C &= \sage{A.adjoint().transpose()} &
    \adj(A) &= C^\top = \sage{A.adjoint()}
  \end{align*}
\end{ex}

\newpage
\begin{thm}[Theorem 1.26 in \cite{peterson}]
  $A\adj(A)=\adj(A)A=\det(A)I$
\end{thm}

\begin{ex}
  For $A=\sage{A}$ we found $\adj(A)=\sage{A.adjoint()}$. Thus
  \[
  A\adj(A)=\sage{A}\sage{A.adjoint()}=\sage{A*A.adjoint()}=\det(A)I
  \]
\end{ex}

\begin{thm}[Corollary 1.27 in \cite{peterson}]
  If $A$ is invertible, then
  \[
  A^{-1}=\frac{1}{\det(A)}\adj(A)
  \]
\end{thm}

\begin{ex}
  For $A=\sage{A}$ we have
  \[
  A^{-1}=\frac{1}{\det(A)}\adj(A)=\frac{1}{\sage{A.det()}}\sage{A.adjoint()}
  \]
  provided that $\sage{A.det()}\neq 0$.
\end{ex}


\newpage

\begin{thm}[Cramer's Rule]
  Consider the system $A\vec x=\vec b$ where $A$ is invertible. Let $A_i$ be the
  matrix obtained by replacing the $i$th column of $A$ by $\vec b$. Then
  $\displaystyle x_i=\frac{\det(A_i)}{\det(A)}$.
\end{thm}

\begin{sagesilent}
  var('a b c d x1 x2 b1 b2')
  A = matrix([[a, b],[c, d]])
  x = matrix.column([x1, x2])
  b = matrix.column([b1, b2])
\end{sagesilent}
\begin{ex}
  Consider $A\vec x=\vec b$ where
  \begin{align*}
    A &= \sage{A} & 
    \vec x &= \sage{x} &
    \vec b &= \sage{b}
  \end{align*}
  and suppose that $A$ is invertible. Then 
  \begin{sagesilent}
    latex.matrix_delimiters(left='|', right='|')
    var('a b c d x1 x2 b1 b2')
    A1 = matrix([[b1, b],[b2, d]])
    A2 = matrix([[a, b1],[c, b2]])
    A = matrix([[a, b],[c, d]])
  \end{sagesilent}
  \begin{align*}
    x_1 &= \frac{\det(A_1)}{\det(A)} = \frac{\sage{A1}}{\sage{A}} = \frac{\sage{A1.det()}}{\sage{A.det()}} \\
    x_2 &= \frac{\det(A_2)}{\det(A)} = \frac{\sage{A2}}{\sage{A}} = \frac{\sage{A2.det()}}{\sage{A.det()}} 
  \end{align*}
\end{ex}



\bibliography{mybib.bib}{}
\bibliographystyle{plain}

\end{document}
